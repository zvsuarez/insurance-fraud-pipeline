{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing as proc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('carclaims.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['PolicyNumber', 'FraudFound'], axis=1)\n",
    "y = df['FraudFound']\n",
    "print(X.shape, y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = LabelEncoder()\n",
    "y_train = label_encode.fit_transform(y_train)\n",
    "y_test = label_encode.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_VAR = ['Month', 'MonthClaimed', 'DayOfWeek', 'DayOfWeekClaimed']\n",
    "\n",
    "NUMERICAL = ['Year', 'Deductible']\n",
    "\n",
    "ONE_HOT_CATEGORICAL = ['Make', 'PolicyType', 'MaritalStatus',\n",
    "                       'BasePolicy','Fault', 'Sex', 'AccidentArea']\n",
    "ORDINAL_CATEGORICAL = ['AgeOfVehicle', 'AgeOfPolicyHolder', 'VehiclePrice',\n",
    "                       'AddressChange-Claim','NumberOfSuppliments', 'PastNumberOfClaims']\n",
    "\n",
    "AGE_OF_VEH_VAR = ['AgeOfVehicle']\n",
    "AGE_OF_POL_VAR = ['AgeOfPolicyHolder']\n",
    "VEH_PRICE_VAR = ['VehiclePrice']\n",
    "ADD_CHANGE_VAR = ['AddressChange-Claim']\n",
    "NUM_SUPP_VAR = ['NumberOfSuppliments']\n",
    "PAST_CLAIM_VAR = ['PastNumberOfClaims']\n",
    "\n",
    "MONTH_MAP = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "DAY_MAP = {'Sunday': 6, 'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5}\n",
    "\n",
    "AGE_OF_VEH_MAP = {'new': 8, '2 years': 7, '3 years': 6, '4 years': 5,\n",
    "                  '5 years': 4, '6 years': 3, '7 years': 2, 'more than 7': 1}\n",
    "AGE_OF_POL_MAP = {'16 to 17': 1, '18 to 20': 2, '21 to 25': 3, '26 to 30': 4,\n",
    "                  '31 to 35': 5, '36 to 40': 6, '41 to 50': 7, '51 to 65': 8,\n",
    "                  'over 65': 9}\n",
    "VEH_PRICE_MAP = {'less than 20,000': 1, '20,000 to 29,000': 2,\n",
    "                 '30,000 to 39,000': 3, '40,000 to 59,000': 4,\n",
    "                 '60,000 to 69,000': 5, 'more than 69,000': 6}\n",
    "\n",
    "ADD_CHANGE_MAP = {'no change': 1, 'under 6 months': 2, '1 year': 3,\n",
    "                  '2 to 3 years': 4, '4 to 8 years': 5}\n",
    "NUM_SUPP_MAP = {'none': 1, '1 to 2': 2, '3 to 5': 3, 'more than 5': 4}\n",
    "PAST_CLAIM_MAP = {'none': 1, '1': 2, '2 to 4': 3, 'more than 4': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'BasePolicy', 'PolicyType', 'Make', 'AccidentArea', 'Fault', 'AgeOfVehicle', 'VehiclePrice', \n",
    "    'Year', 'Month', 'MonthClaimed', 'DayOfWeek', 'DayOfWeekClaimed', 'Sex', 'MaritalStatus', 'AgeOfPolicyHolder',\n",
    "    'Deductible','AddressChange-Claim', 'NumberOfSuppliments', 'PastNumberOfClaims'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transform = ColumnTransformer(\n",
    "    transformers=[\n",
    "    ('map_month', proc.MapTransform(variable=TEMP_VAR[:2], mappings=MONTH_MAP), TEMP_VAR[:2]),\n",
    "    ('map_day', proc.MapTransform(variable=TEMP_VAR[2:], mappings=DAY_MAP), TEMP_VAR[2:]),\n",
    "    ('age_veh', proc.MapTransform(variable=AGE_OF_VEH_VAR, mappings=AGE_OF_VEH_MAP), AGE_OF_VEH_VAR),\n",
    "    ('age_pol', proc.MapTransform(variable=AGE_OF_POL_VAR, mappings=AGE_OF_POL_MAP), AGE_OF_POL_VAR),\n",
    "    ('veh_price', proc.MapTransform(variable=VEH_PRICE_VAR, mappings=VEH_PRICE_MAP), VEH_PRICE_VAR),\n",
    "    ('add_change', proc.MapTransform(variable=ADD_CHANGE_VAR, mappings=ADD_CHANGE_MAP), ADD_CHANGE_VAR),\n",
    "    ('num_supp', proc.MapTransform(variable=NUM_SUPP_VAR, mappings=NUM_SUPP_MAP), NUM_SUPP_VAR),\n",
    "    ('past_claim', proc.MapTransform(variable=PAST_CLAIM_VAR, mappings=PAST_CLAIM_MAP), PAST_CLAIM_VAR),\n",
    "    ('hot_cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), ONE_HOT_CATEGORICAL)\n",
    "    ], remainder='passthrough'\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for feature in TEMP_VAR:\n",
    "    if feature == 'DayOfWeekClaimed' or feature == 'DayOfWeek':\n",
    "        X_train[feature] = X_train[feature].replace('0', 'Monday')\n",
    "        X_test[feature] = X_test[feature].replace('0', 'Monday')\n",
    "    if feature == 'MonthClaimed' or feature == 'Month':\n",
    "        X_train[feature] = X_train[feature].replace('0', 'Jan')\n",
    "        X_test[feature] = X_test[feature].replace('0', 'Jan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampler = RandomUnderSampler(random_state=42, sampling_strategy={0:6000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrainsamp = col_transform.fit_transform(X_train)\n",
    "xtrainsamp, ytrainsamp = sampler.fit_resample(xtrainsamp, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reindexed = proc.ResetIndexTransform().fit_transform(xtrainsamp)\n",
    "reindexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.any(np.isnan(ytrainsamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clean', proc.CleanTransform(variable=TEMP_VAR)),\n",
    "    ('transform', col_transform),\n",
    "    ('undersamp', RandomUnderSampler(random_state=42, sampling_strategy={0:5000})),\n",
    "    ('reindex', proc.ResetIndexTransform()),\n",
    "    ('oversamp', SMOTE(random_state=42)),\n",
    "    ('cos_sin_transform', proc.CoSineTransform(['map_month__Month', 'map_month__MonthClaimed',\n",
    "       'map_day__DayOfWeek', 'map_day__DayOfWeekClaimed'])),\n",
    "    ('drop', proc.DropTransform(['map_month__Month', 'map_month__MonthClaimed',\n",
    "       'map_day__DayOfWeek', 'map_day__DayOfWeekClaimed'])),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, step in pipeline.named_steps.items():\n",
    "    print(f'[DEBUG]: Checking step {name}...')\n",
    "\n",
    "    try:\n",
    "        if name == 'undersamp' or name =='oversamp':\n",
    "            X_transformed = step.fit_resample(X, y)\n",
    "        else:\n",
    "            X_transformed = step.fit_transform(X, y)\n",
    "\n",
    "        print(f'Shape: {X_transformed.shape}')\n",
    "        print(f'Number of NaNs: \\n{pd.DataFrame(X_transformed).isna().sum()}')\n",
    "    except Exception as err:\n",
    "        print(f'Error in step: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pipeline.predict(X_train)\n",
    "pred_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, pred_train, target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test, target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_strategy = [\n",
    "    {0:9000}, {0:7000}, {0:5000}, {0:3000}\n",
    "]\n",
    "\n",
    "os_strategy = [\n",
    "    {1:9000}, {1:7000}, {1:5000}, {1:3000}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'undersamp__sampling_strategy': us_strategy,\n",
    "    'oversamp__sampling_strategy': os_strategy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=pipeline, param_grid=grid_params, n_jobs=-1, cv=5, error_score='raise')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)\n",
    "#Output -> {'oversampler__sampling_strategy': {1: 5000}, 'undersampler__sampling_strategy': {0: 200000}}\n",
    "hp_best_pipeline  = clf.best_estimator_\n",
    "print(hp_best_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_best_pipeline.fit(X_train, y_train)\n",
    "predictions_hp = hp_best_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, predictions_hp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,  # Limit depth to prevent overfitting\n",
    "    min_samples_leaf=5,  # Minimum samples per leaf\n",
    "    min_samples_split=10,  # Minimum samples to split a node\n",
    "    max_features='sqrt',  # Use fewer features per split\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'classifier__n_estimators': [10, 50, 100],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
