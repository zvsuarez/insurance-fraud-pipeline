{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import model_dev.preprocessing as proc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, auc, average_precision_score, classification_report\n",
    "from sklearn.metrics import det_curve, roc_curve, precision_recall_curve, confusion_matrix\n",
    "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay, DetCurveDisplay, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import joblib\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('carclaims.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['PolicyNumber', 'FraudFound'], axis=1)\n",
    "y = df['FraudFound']\n",
    "print(X.shape, y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = LabelEncoder()\n",
    "y_train_enc = label_encode.fit_transform(y_train)\n",
    "y_test_enc = label_encode.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_VAR = ['Month', 'MonthClaimed', 'DayOfWeek']\n",
    "\n",
    "NUM_VAR = ['DriverRating']\n",
    "\n",
    "ONE_HOT_CAT_VAR = ['Make', 'PolicyType', 'MaritalStatus', 'VehicleCategory',\n",
    "                       'BasePolicy', 'AgentType', 'WitnessPresent', \n",
    "                       'PoliceReportFiled', 'Fault', 'Sex', 'AccidentArea']\n",
    "\n",
    "ORDINAL_CAT_VAR = ['NumberOfCars', 'Days:Policy-Claim']\n",
    "\n",
    "NUM_CAR_VAR = ['NumberOfCars']\n",
    "DAYS_CLAIM_VAR = ['Days:Policy-Claim']\n",
    "\n",
    "MONTH_MAP = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "DAY_MAP = {'Sunday': 6, 'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5}\n",
    "NUM_CAR_MAP = {'1 vehicle': 1, '2 vehicles': 2, '3 to 4': 3, '5 to 8': 4, 'more than 8': 5}\n",
    "DAYS_CLAIM_MAP = {'none':1, '8 to 15': 2, '15 to 30': 3, 'more than 30': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'Make',\n",
    "    'PolicyType',\n",
    "    'BasePolicy',\n",
    "    'MaritalStatus',\n",
    "    'Sex',\n",
    "    'VehicleCategory',\n",
    "    'AgentType',\n",
    "    'WitnessPresent',\n",
    "    'PoliceReportFiled',\n",
    "    'AccidentArea',\n",
    "    'NumberOfCars',\n",
    "    'Fault',\n",
    "    'Month',\n",
    "    'MonthClaimed',\n",
    "    'DayOfWeek',\n",
    "    'Days:Policy-Claim',\n",
    "    'DriverRating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column transformers for Random Forest (One Hot Encoding + Scaling)\n",
    "cat_transform = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), ONE_HOT_CAT_VAR)\n",
    "    ], remainder='passthrough'\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean -> map -> cos/sin -> drop -> onehot -> sampling -> classify\n",
    "pipeline = Pipeline([\n",
    "    ('clean', proc.CleanTransform(variable=TEMP_VAR)),\n",
    "    ('map_month', proc.MapTransform(variable=TEMP_VAR[:2], mappings=MONTH_MAP)),\n",
    "    ('map_day', proc.MapTransform(variable=[TEMP_VAR[-1]], mappings=DAY_MAP)),\n",
    "    ('map_num', proc.MapTransform(variable=NUM_CAR_VAR, mappings=NUM_CAR_MAP)),\n",
    "    ('map_claim', proc.MapTransform(variable=DAYS_CLAIM_VAR, mappings=DAYS_CLAIM_MAP)),\n",
    "    ('cos_sin', proc.CoSineTransform(variable=TEMP_VAR)),\n",
    "    ('drop', proc.DropTransform(variable=TEMP_VAR)),\n",
    "    ('one_hot', cat_transform),\n",
    "    ('sampler', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=300, criterion='gini', random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pipeline.predict(X_train)\n",
    "pred_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = accuracy_score(y_train_enc, pred_train)\n",
    "print(f'train accuracy: {acc_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = accuracy_score(y_test_enc, pred_test)\n",
    "print(f'test accuracy: {acc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_train_enc, pred_train, target_names=['Not Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test_enc, pred_test, target_names=['Not Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train_enc, pipeline.predict_proba(X_train)[:, 1], pos_label=1)\n",
    "#pos_label=1\n",
    "roc_auc_train = roc_auc_score(y_train_enc, pipeline.predict_proba(X_train)[:, 1])\n",
    "print(f'false positive: {fpr_train}\\ntrue positive: {tpr_train}\\nthreshold: {thresholds_train}')\n",
    "print(f'auc: {auc(fpr_train, tpr_train)}')\n",
    "print(f'roc_auc: {roc_auc_train}')\n",
    "roc_tr_plot = RocCurveDisplay(fpr=fpr_train, tpr=tpr_train, roc_auc=roc_auc_train, pos_label=1).plot()\n",
    "#pos_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test_enc, pipeline.predict_proba(X_test)[:, 1], pos_label=1)\n",
    "#pos_label=1\n",
    "roc_auc_test = roc_auc_score(y_test_enc, pipeline.predict_proba(X_test)[:, 1])\n",
    "print(f'false positive: {fpr_test}\\ntrue positive: {tpr_test}\\nthreshold: {thresholds_test}')\n",
    "print(f'auc: {auc(fpr_test, tpr_test)}')\n",
    "print(f'roc_auc: {roc_auc_test}')\n",
    "roc_ts_plot = RocCurveDisplay(fpr=fpr_test, tpr=tpr_test, roc_auc=roc_auc_test, pos_label=1).plot()\n",
    "#pos_label=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_train, recall_train, _ = precision_recall_curve(y_train_enc, pipeline.predict_proba(X_train)[:, 1], pos_label=1)\n",
    "#pos_label = 1\n",
    "avg_train = average_precision_score(y_train_enc, pipeline.predict_proba(X_train)[:, 1], pos_label=1)\n",
    "prc_tr_plot = PrecisionRecallDisplay(precision=precision_train, recall=recall_train, average_precision=avg_train, estimator_name='RandomForestClassifier', pos_label=1).plot()\n",
    "#pos_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test, recall_test, _ = precision_recall_curve(y_test_enc, pipeline.predict_proba(X_test)[:, 1], pos_label=1)\n",
    "#pos_label = 1\n",
    "avg_test = average_precision_score(y_test_enc, pipeline.predict_proba(X_test)[:, 1], pos_label=1)\n",
    "prc_ts_plot = PrecisionRecallDisplay(precision=precision_test, recall=recall_test, average_precision=avg_test, estimator_name='RandomForestClassifier', pos_label=1).plot()\n",
    "#pos_label = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dt_train, fnr_dt_train, treshold_dt_train = det_curve(y_train_enc, pipeline.predict_proba(X_train)[:, 1], pos_label=1)\n",
    "fpr_dt_test, fnr_dt_test, treshold_dt_test = det_curve(y_test_enc, pipeline.predict_proba(X_test)[:, 1], pos_label=1)\n",
    "dt_tr_plot = DetCurveDisplay(fpr=fpr_dt_train, fnr=fnr_dt_train, estimator_name='RandomForestClassifier', pos_label=1)\n",
    "dt_ts_plot = DetCurveDisplay(fpr=fpr_dt_test, fnr=fnr_dt_test, estimator_name='RandomForestClassifier', pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(3, 3, figsize=(12, 10))\n",
    "roc_tr_plot.plot(ax=ax1)\n",
    "prc_tr_plot.plot(ax=ax2)\n",
    "dt_tr_plot.plot(ax=ax3)\n",
    "roc_ts_plot.plot(ax=ax4)\n",
    "prc_ts_plot.plot(ax=ax5)\n",
    "dt_ts_plot.plot(ax=ax6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train_enc, pred_train)\n",
    "ConfusionMatrixDisplay(cm_train).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test_enc, pred_test)\n",
    "ConfusionMatrixDisplay(cm_test).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipeline, 'rf_pipeline.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
