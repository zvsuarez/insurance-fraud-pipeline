{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import preprocessing as proc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('carclaims.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['PolicyNumber', 'FraudFound'], axis=1)\n",
    "y = df['FraudFound']\n",
    "print(X.shape, y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True)\n",
    "X_train.drop(columns='index', inplace=True)\n",
    "X_test.reset_index(inplace=True)\n",
    "X_test.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=y_train)\n",
    "fraud_ratio = round((y_test == 'Yes').sum() / len(df) * 100, ndigits=4)\n",
    "plt.yticks(np.arange(0, 13000, 1000))\n",
    "print(f'Fraud ratio: {fraud_ratio}%')\n",
    "print(f'Fraud count: {(y_train == \"Yes\").sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wide imbalance warrants resampling. In this manner, random oversampling (ROS) will be used.\n",
    "\n",
    "From the study of PÃ©rez, et. al, (2022): FS+ROS is the best balancing configuration when using (Random Forest) RF as the classifier. [Link to the paper](https://www.sciencedirect.com/science/article/pii/S0957417421013622#:~:text=Some%20general%20conclusions%20of%20the,better%20results%20when%20applied%20afterwards.)\n",
    "\n",
    "\"RF: The balancing configuration FS+ROS in the area plots, and FS+RUS in the average ranks, showed better performance than the others. Unlike C4.5, the rankings showed that no use of balancing was by far the worst combination, a behavior also supported by the results of a previous study (Pes, 2020).\"\n",
    "\n",
    "\"On the contrary, the results suggest that, in general, SMOTE and ROS perform better if applied after feature selection.\"\n",
    "\n",
    "Feature selection will be conducted to find the best set of features. Based on the same study: ANOVA as the feature selector yields a viable percentage of victories for FS+ROS compared to other selectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM will be tested with SelectFromModel alongside the ANOVA selectors to compare the differences of available features when it comes to the differences of weights vs the variances with f-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_REPLACE = ['Month', 'MonthClaimed', \n",
    "                 'DayOfWeek', 'DayOfWeekClaimed',\n",
    "                 'WeekOfMonth', 'WeekOfMonthClaimed']\n",
    "\n",
    "TEMP_SIN_COS = ['Month', 'MonthClaimed', 'DayOfWeek', 'DayOfWeekClaimed']\n",
    "\n",
    "AGE = ['Age']\n",
    "\n",
    "ONE_HOT_NUMERICAL = ['WeekOfMonth', 'WeekOfMonthClaimed', 'RepNumber']\n",
    "ONE_HOT_CATEGORICAL = ['Make', 'PolicyType', 'MaritalStatus', 'VehicleCategory',\n",
    "                       'BasePolicy', 'AgentType', 'WitnessPresent', \n",
    "                       'PoliceReportFiled', 'Fault', 'Sex', 'AccidentArea']\n",
    "\n",
    "\"\"\"ORDINAL_CATEGORICAL = ['AgeOfVehicle', 'AgeOfPolicyHolder', 'VehiclePrice',\n",
    "                       'Days:Policy-Accident', 'NumberOfCars', 'AddressChange-Claim',\n",
    "                       'NumberOfSuppliments', 'PastNumberOfClaims', 'Days:Policy-Claim']\n",
    "                       \"\"\"\n",
    "\n",
    "AGE_OF_VEH_VAR = ['AgeOfVehicle']\n",
    "AGE_OF_POL_VAR = ['AgeOfPolicyHolder']\n",
    "VEH_PRICE_VAR = ['VehiclePrice']\n",
    "DAYS_ACC_VAR = ['Days:Policy-Accident']\n",
    "NUM_CAR_VAR = ['NumberOfCars']\n",
    "ADD_CHANGE_VAR = ['AddressChange-Claim']\n",
    "NUM_SUPP_VAR = ['NumberOfSuppliments']\n",
    "PAST_CLAIM_VAR = ['PastNumberOfClaims']\n",
    "DAYS_CLAIM_VAR = ['Days:Policy-Claim']\n",
    "\n",
    "MONTH_MAP = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "DAY_MAP = {'Sunday': 6, 'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5}\n",
    "AGE_OF_VEH_MAP = {'new': 8, '2 years': 7, '3 years': 6, '4 years': 5,\n",
    "                  '5 years': 4, '6 years': 3, '7 years': 2, 'more than 7': 1}\n",
    "AGE_OF_POL_MAP = {'16 to 17': 1, '18 to 20': 2, '21 to 25': 3, '26 to 30': 4,\n",
    "                  '31 to 35': 5, '36 to 40': 6, '41 to 50': 7, '51 to 65': 8,\n",
    "                  'over 65': 9}\n",
    "VEH_PRICE_MAP = {'less than 20,000': 1, '20,000 to 29,000': 2,\n",
    "                 '30,000 to 39,000': 3, '40,000 to 59,000': 4,\n",
    "                 '60,000 to 69,000': 5, 'more than 69,000': 6}\n",
    "DAYS_ACC_MAP = {'none': 1, '1 to 7': 2, '8 to 15': 3, '15 to 30': 4, 'more than 30': 5}\n",
    "NUM_CAR_MAP = {'1 vehicle': 1, '2 vehicles': 2, '3 to 4': 3, '5 to 8': 4}\n",
    "ADD_CHANGE_MAP = {'no change': 1, 'under 6 months': 2, '1 year': 3,\n",
    "                  '2 to 3 years': 4, '4 to 8 years': 5}\n",
    "NUM_SUPP_MAP = {'none': 1, '1 to 2': 2, '3 to 5': 3, 'more than 5': 4}\n",
    "PAST_CLAIM_MAP = {'none': 1, '1': 2, '2 to 4': 3, 'more than 4': 4}\n",
    "DAYS_CLAIM_MAP = {'8 to 15': 1, '15 to 30': 2, 'more than 30': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in TEMP_REPLACE:\n",
    "    if feature == 'DayOfWeekClaimed' or feature == 'DayOfWeek':\n",
    "        X_train[feature] = X_train[feature].replace('0', 'Monday')\n",
    "        X_test[feature] = X_test[feature].replace('0', 'Monday')\n",
    "    if feature == 'WeekOfMonthClaimed' or feature == 'WeekOfMonth':\n",
    "        X_train[feature] = X_train[feature].replace('0', 1)\n",
    "        X_test[feature] = X_test[feature].replace('0', 1)\n",
    "    if feature == 'MonthClaimed' or feature == 'Month':\n",
    "        X_train[feature] = X_train[feature].replace('0', 'Jan')\n",
    "        X_test[feature] = X_test[feature].replace('0', 'Jan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in TEMP_SIN_COS:\n",
    "    if feature == 'MonthClaimed' or feature == 'Month':\n",
    "        X_train[feature] = X_train[feature].map(MONTH_MAP)\n",
    "        X_test[feature] = X_test[feature].map(MONTH_MAP)\n",
    "    if feature == 'DayOfWeekClaimed' or feature == 'DayOfWeek':\n",
    "        X_train[feature] = X_train[feature].map(DAY_MAP)\n",
    "        X_test[feature] = X_test[feature].map(DAY_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in TEMP_SIN_COS:\n",
    "    if feature == 'MonthClaimed' or feature == 'Month':\n",
    "        X_train[feature+'_sin'] = np.sin(2 * np.pi * X_train[feature] / 12)\n",
    "        X_train[feature+'_cos'] = np.cos(2 * np.pi * X_train[feature] / 12)\n",
    "        \n",
    "        X_test[feature+'_sin'] = np.sin(2 * np.pi * X_test[feature] / 12)\n",
    "        X_test[feature+'_cos'] = np.cos(2 * np.pi * X_test[feature] / 12)\n",
    "        \n",
    "    if feature == 'DayOfWeekClaimed' or feature == 'DayOfWeek':\n",
    "        X_train[feature+'_sin'] = np.sin(2 * np.pi * X_train[feature] / 7)\n",
    "        X_train[feature+'_cos'] = np.cos(2 * np.pi * X_train[feature] / 7)\n",
    "\n",
    "        X_test[feature+'_sin'] = np.sin(2 * np.pi * X_test[feature] / 7)\n",
    "        X_test[feature+'_cos'] = np.cos(2 * np.pi * X_test[feature] / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['MonthClaimed', 'Month'], inplace=True)\n",
    "X_test.drop(columns=['MonthClaimed', 'Month'], inplace=True)\n",
    "X_train.drop(columns=['DayOfWeekClaimed', 'DayOfWeek'], inplace=True)\n",
    "X_test.drop(columns=['DayOfWeekClaimed', 'DayOfWeek'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "mean_train = X_train[X_train['Age'] > 0]['Age'].mean()\n",
    "mean_test = X_test[X_test['Age'] > 0]['Age'].mean()\n",
    "\n",
    "for feature in AGE:\n",
    "    X_train[feature] = X_train[feature].apply(lambda z: mean_train if z <=0 else z)\n",
    "    X_test[feature] = X_test[feature].apply(lambda z: mean_test if z <=0 else z)\n",
    "    \n",
    "    X_train[feature], _ = stats.boxcox(X_train[feature])\n",
    "    X_test[feature], _ = stats.boxcox(X_test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('hot_num', OneHotEncoder(), ONE_HOT_NUMERICAL),\n",
    "        ('hot_cat', OneHotEncoder(), ONE_HOT_CATEGORICAL),\n",
    "        ('age_veh', proc.MapTransform(AGE_OF_VEH_VAR, AGE_OF_VEH_MAP), AGE_OF_VEH_VAR),\n",
    "        ('age_pol', proc.MapTransform(AGE_OF_POL_VAR, AGE_OF_POL_MAP), AGE_OF_POL_VAR),\n",
    "        ('veh_price', proc.MapTransform(VEH_PRICE_VAR, VEH_PRICE_MAP), VEH_PRICE_VAR),\n",
    "        ('day_acc', proc.MapTransform(DAYS_ACC_VAR, DAYS_ACC_MAP), DAYS_ACC_VAR),\n",
    "        ('num_car', proc.MapTransform(NUM_CAR_VAR, NUM_CAR_MAP), NUM_CAR_VAR),\n",
    "        ('add_change', proc.MapTransform(ADD_CHANGE_VAR, ADD_CHANGE_MAP), ADD_CHANGE_VAR),\n",
    "        ('num_supp', proc.MapTransform(NUM_SUPP_VAR, NUM_SUPP_MAP), NUM_SUPP_VAR),\n",
    "        ('past_claim', proc.MapTransform(PAST_CLAIM_VAR, PAST_CLAIM_MAP), PAST_CLAIM_VAR),\n",
    "        ('day_claim', proc.MapTransform(DAYS_CLAIM_VAR, DAYS_CLAIM_MAP), DAYS_CLAIM_VAR)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "anova_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('hot_num', OneHotEncoder(), ONE_HOT_NUMERICAL),\n",
    "        ('hot_cat', OneHotEncoder(), ONE_HOT_CATEGORICAL),\n",
    "        ('age_veh', proc.MapTransform(AGE_OF_VEH_VAR, AGE_OF_VEH_MAP), AGE_OF_VEH_VAR),\n",
    "        ('age_pol', proc.MapTransform(AGE_OF_POL_VAR, AGE_OF_POL_MAP), AGE_OF_POL_VAR),\n",
    "        ('veh_price', proc.MapTransform(VEH_PRICE_VAR, VEH_PRICE_MAP), VEH_PRICE_VAR),\n",
    "        ('day_acc', proc.MapTransform(DAYS_ACC_VAR, DAYS_ACC_MAP), DAYS_ACC_VAR),\n",
    "        ('num_car', proc.MapTransform(NUM_CAR_VAR, NUM_CAR_MAP), NUM_CAR_VAR),\n",
    "        ('add_change', proc.MapTransform(ADD_CHANGE_VAR, ADD_CHANGE_MAP), ADD_CHANGE_VAR),\n",
    "        ('num_supp', proc.MapTransform(NUM_SUPP_VAR, NUM_SUPP_MAP), NUM_SUPP_VAR),\n",
    "        ('past_claim', proc.MapTransform(PAST_CLAIM_VAR, PAST_CLAIM_MAP), PAST_CLAIM_VAR),\n",
    "        ('day_claim', proc.MapTransform(DAYS_CLAIM_VAR, DAYS_CLAIM_MAP), DAYS_CLAIM_VAR)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svc = svc_preprocessor.fit_transform(X_train)\n",
    "X_test_svc = svc_preprocessor.transform(X_test)\n",
    "X_train_anova = anova_preprocessor.fit_transform(X_train)\n",
    "X_test_anova = anova_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_label_bin = LabelBinarizer()\n",
    "anova_label_bin = LabelBinarizer()\n",
    "\n",
    "y_train_svc = svc_label_bin.fit_transform(y_train)\n",
    "y_test_svc = svc_label_bin.transform(y_test)\n",
    "y_train_anova = anova_label_bin.fit_transform(y_train)\n",
    "y_test_anova = anova_label_bin.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_selector = SelectFromModel(SVC(probability=True, random_state=42))\n",
    "svc_selector.fit(X_train_svc, y_train_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svc_selector.get_support().sum())\n",
    "svc_selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_selected = X_train.columns[(svc_selector.get_support())]\n",
    "\n",
    "print(f'total features: {X_train.shape[1]}')\n",
    "print(f'selected features: {len(svc_selected)}')\n",
    "print(f'features with coef shrank to 0: {np.sum(svc_selector.estimator_.coef_ == 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_selector = SelectKBest(f_classif, k='all')\n",
    "anova_selector.fit(X_train_anova, y_train_anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('feature importance: ', anova_selector.scores_)\n",
    "print('pvalues: ', anova_selector.pvalues_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_stats = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Score': anova_selector.scores_,\n",
    "    'P-Value': anova_selector.pvalues_\n",
    "})\n",
    "\n",
    "feature_stats.sort_values(by='Score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anova_selector.get_support().sum())\n",
    "anova_selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_selected = X_train.columns[(anova_selector.get_support())]\n",
    "\n",
    "print(f'total features: {X_train.shape[1]}')\n",
    "print(f'selected features: {len(anova_selected)}')\n",
    "print(f'features with coef shrank to 0: {np.sum(anova_selector.estimator_.coef_ == 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_res).items()))\n",
    "print(X_res.shape, y_res.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
